{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYuRiZrZQnhvw7xpkANfta",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dnyanu25/python-learning/blob/main/Question_Section_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Questions"
      ],
      "metadata": {
        "id": "aC2cwjLXRpV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What does â€œChat Completion Modelâ€ mean ?**\n",
        "\n",
        "=>\n",
        "A chat completion model is an AI model that generates the next reply in a conversation, based on all previous messages.\n",
        "\n",
        "ðŸ”¹ Break the term into 2 parts\n",
        "\n",
        "**1ï¸âƒ£ Chat**\n",
        "\n",
        "Means conversation\n",
        "\n",
        "Multiple messages\n",
        "\n",
        "Roles like:user,assistant,system\n",
        "\n",
        "**2ï¸âƒ£ Completion**\n",
        "\n",
        "The model completes the conversation\n",
        "\n",
        "It predicts what should be said next\n",
        "\n",
        "So together:\n",
        "\n",
        "**Chat Completion = Completing the next message in a chat**\n",
        "\n",
        "\n",
        "---\n",
        "****\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6awV0VGaRtO4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# questions"
      ],
      "metadata": {
        "id": "AqSlQglQR0l8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. what is an api**\n",
        "\n",
        "=>An Appliaction Programming interface allows two software systems to communicate.\n",
        "it is a bridge that let your program to talk to another device.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**2. What is an API Key**\n",
        "\n",
        "=>An API Key is a secret token used to autheticate and autorize a user while accessing an api\n",
        "it tells the api who you are and what access you have.\n",
        "\n",
        "---\n",
        "\n",
        "**3.why should be api keys be kept secret?**\n",
        "\n",
        "=> if someone gets your API key they can\n",
        "\n",
        "*use your quota\n",
        "\n",
        "*generate bills\n",
        "\n",
        "*misuse your account details\n",
        "\n",
        "so api keys should be stored secretlyin envirnment variables\n",
        "instead of code.\n",
        "\n",
        "```\n",
        "ex os.getenv(\"GROQ_API_KEY\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "**4. WHY DO WE USE .ENV OR USERDATA IN COLLAB**\n",
        "\n",
        "=>\n",
        "Because they:  \n",
        "1.hide secret keys (like api key)\n",
        "\n",
        "2.code can be shared secretely\n",
        "\n",
        "3.keys can be changed without modifying code\n",
        "\n",
        "---\n",
        "****\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "L-yyVx4BR5Uh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat Completion Fundamentals"
      ],
      "metadata": {
        "id": "SqbeqIcuUyfI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. What is chat completion Model?**\n",
        "\n",
        "=>A Chat Completion model generates responces based on  :    \n",
        "1 System instructions\n",
        "\n",
        "2 User messages\n",
        "\n",
        "3 Conversation history\n",
        "\n",
        "it is designed for **Conversion based tasks**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**8. Difference between Text Completion and chat Completion?**\n",
        "\n",
        "\n",
        "=>Text Completion.........          chat Completion\n",
        "\n",
        "TC:single prompt .........          CC:Multi-message\n",
        "\n",
        "\n",
        "TC:No roles      .................   CC: userroles(System,user,assistant)\n",
        "\n",
        "TC:No Memory     .........          CC: Support conversation\n",
        "\n",
        "---\n",
        "\n",
        "**9. What are roles in chat completion?**\n",
        "\n",
        "=>\n",
        "System=rules and behaviour\n",
        "\n",
        "User=instructions and Questions\n",
        "\n",
        "Assistant=AI Responses\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**10. Why is System Role important ?**\n",
        "\n",
        "\n",
        "=>it set the behaviour and personality of the model.\n",
        "for ex\n",
        "```\n",
        "You are a helpful AI Agent\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "**11. Can the model remember Past conversaction automatically?.**\n",
        "\n",
        "\n",
        "=>No\n",
        "\n",
        "The model is stateless\n",
        "\n",
        "We must send conversaction history every time.\n",
        "\n",
        "---\n",
        "****\n"
      ],
      "metadata": {
        "id": "JYtDoen6VMSZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GROQ + LLM Basics"
      ],
      "metadata": {
        "id": "2JDRuczLbDjB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**12.what is Groq**\n",
        "\n",
        "=>\n",
        "Groq is an AI interface platform optimized for ultra fast LLM execution using LPU hardware.\n",
        "\n",
        "---\n",
        "\n",
        "**13. Why use Groq instead of OpenAI?**\n",
        "\n",
        "=>\n",
        "\n",
        "Faster Responce\n",
        "\n",
        "Free tier\n",
        "\n",
        "Low latency\n",
        "\n",
        "Open models(LLaMA)\n",
        "\n",
        "---\n",
        "\n",
        "**14. What is LLaMA?**\n",
        "\n",
        "=>\n",
        "LLaMA is a Family of open-source language models developed by Meta.\n",
        "\n",
        "---\n",
        "\n",
        "**15.what does this mean?**\n",
        "\n",
        "```\n",
        "model=\"llama-3.1-8b-instant\"\n",
        "```\n",
        "\n",
        "\n",
        "**=>**\n",
        "\n",
        "3.1=>model version\n",
        "\n",
        "8b=>8billion parameters\n",
        "\n",
        "instant=>optimized for speed\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**16. Why did older models fails?**\n",
        "\n",
        "\n",
        "=>\n",
        "They were decommissioned and no longer supported by Groq\n",
        "\n",
        "\n",
        "---\n",
        "****\n",
        "\n"
      ],
      "metadata": {
        "id": "pz7pepLKbN5_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent Fundamentals"
      ],
      "metadata": {
        "id": "7S3zoGpnglRi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**17. What is an AI Agent?**\n",
        "\n",
        "=> An AI Agent is an autonomous entity that:\n",
        "\n",
        "observe input\n",
        "\n",
        "Think using an LLM\n",
        "\n",
        "Acts by generating output\n",
        "\n",
        "Maintains memory\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**18. Difference Between LLM And Agent?**\n",
        "\n",
        "=>\n",
        "LLM:Brain and Agent:Brain+Memory+Logic\n",
        "\n",
        "LLM:Stateless And Agent:Stateful\n",
        "\n",
        "LLM:OneShot And Agent:Continuous interaction\n",
        "\n",
        "---\n",
        "\n",
        "**19.What is Agent Memory?**\n",
        "\n",
        "=>\n",
        "Agent Memeory Stores Conversaction Context that help the Agent Behave Consistently Across turns.\n",
        "\n",
        "---\n",
        "\n",
        "**20. Why use Python list for Memeory?**\n",
        "\n",
        "=>\n",
        "list is :    \n",
        "ordered\n",
        "\n",
        "Easy to append\n",
        "\n",
        "Compatible with chat APIs\n",
        "\n",
        "---\n",
        "\n",
        "**21. Why DIctionary Format for messages?**\n",
        "\n",
        "=>\n",
        "Chat APIs expect messages as:\n",
        "```\n",
        "{\"role\":\"user\",\"Content\":\".....\"}\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iMYx_ltugqjf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observe-Think-Act Loop"
      ],
      "metadata": {
        "id": "UgfrtPydkyqs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**22.What is Observe-Think-Act?**\n",
        "\n",
        "=>\n",
        "Observe:- capture input\n",
        "\n",
        "Think:-Reason using LLM\n",
        "\n",
        "Act:-Respond/Output\n",
        "\n",
        "This Loop allows continuous intelligent behaviour.\n",
        "\n",
        "---\n",
        "\n",
        "**23. why is this loop important?**\n",
        "\n",
        "=>\n",
        "it mimics human desion making and enables autonmy\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**24. where does memory update happen?**\n",
        "\n",
        "=>\n",
        "userinput:- in observe()\n",
        "\n",
        "LLM Responce:-in think()\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**25. How does the model know the last message?**\n",
        "\n",
        "=>\n",
        "beacuase:\n",
        "\n",
        "Entire Conversaction is sent\n",
        "\n",
        ".Attentation Naturally focuses on latest Input\n",
        "\n",
        "---\n",
        "****\n",
        "\n"
      ],
      "metadata": {
        "id": "9xoa43nZk8X9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Memory Mechanism"
      ],
      "metadata": {
        "id": "GDF_5S3dIRQ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**26.Does Model access memory directly?**\n",
        "\n",
        "=>No\n",
        "Developer provides memory as input\n",
        "\n",
        "---\n",
        "\n",
        "**27. What happen if Memory is not sent?**\n",
        "\n",
        "=>Then model Behaves like this is a new conversaction.\n",
        "\n",
        "---\n",
        "\n",
        "**28.Why does receny message matter more?**\n",
        "\n",
        "=>Transformer attention prioritizes newer tokens\n",
        "\n",
        "---\n",
        "\n",
        "**29 What happens if memory becomes too large? **\n",
        "\n",
        "=>\n",
        "\n",
        ".Token Limit exceeded\n",
        "\n",
        ".increased cost\n",
        "\n",
        ".Slower response\n",
        "\n",
        "---\n",
        "\n",
        "**30 How To Solve Large Memory  Problem ?**\n",
        "\n",
        "=>\n",
        "\n",
        ".Truncate old messages\n",
        "\n",
        ".Summarize memeory\n",
        "\n",
        ".Store long term memory separately\n",
        "\n",
        "---\n",
        "\n",
        "****\n",
        "\n"
      ],
      "metadata": {
        "id": "C8eHoBuMIZPB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Error Handling And Debugging"
      ],
      "metadata": {
        "id": "vRHnC3_xLYa2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**31.Why use try-except?**\n",
        "\n",
        "=>\n",
        "To Prevent Program Crash when\n",
        "\n",
        ".Api Fails\n",
        "\n",
        ".Network issues occur\n",
        "\n",
        ".Invalid input is given\n",
        "\n",
        "---\n",
        "\n",
        "**32. Common Api Errors ?**\n",
        "\n",
        "=>\n",
        ".Model decommissioned\n",
        "\n",
        ".Invalid Request format\n",
        "\n",
        ".Authentication Error\n",
        "\n",
        "---\n",
        "\n",
        "**33. Why is client created only once ?**\n",
        "\n",
        "=>\n",
        "TO Improve :\n",
        "\n",
        ".Performance\n",
        "\n",
        ".Efficiency\n",
        "\n",
        ".Code Clarity\n",
        "\n",
        "---\n",
        "\n",
        "***\n",
        "\n"
      ],
      "metadata": {
        "id": "khlnk7hhLejQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OOP Concepts Used"
      ],
      "metadata": {
        "id": "pc9sk8EwNy8V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**34.Why use a class for agent ? **\n",
        "\n",
        "=>\n",
        "class Allows:\n",
        "\n",
        ".State management\n",
        "\n",
        ".Reusability\n",
        "\n",
        ".Encapsulation\n",
        "\n",
        ".Multiple Agent\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**35.Why is OOP Important for agents?**\n",
        "\n",
        "=> Because Agent Need :    \n",
        ".1.Identity\n",
        "\n",
        "2.Memory\n",
        "\n",
        "3.Behaviour\n",
        "\n",
        "4.Scalability\n",
        "\n",
        "---\n",
        "****"
      ],
      "metadata": {
        "id": "gtKbYffBN-zZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Agent Architecture\n",
        "\n",
        "\n",
        "**: I Built Python-based Conversactional Ai Agent Using Groq's LLaMA Model , implememting OBSERVE-THINK-ACT logic with memeory reply to simulate stateful intelligence.**"
      ],
      "metadata": {
        "id": "E91r6CpUPZqM"
      }
    }
  ]
}
