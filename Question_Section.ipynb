{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMD98sNHISK+7V+ZylnXdC0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dnyanu25/python-learning/blob/main/Question_Section.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Questions"
      ],
      "metadata": {
        "id": "aC2cwjLXRpV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What does â€œChat Completion Modelâ€ mean?**\n",
        "\n",
        "=>\n",
        "A chat completion model is an AI model that generates the next reply in a conversation, based on all previous messages.\n",
        "\n",
        "ðŸ”¹ Break the term into 2 parts\n",
        "\n",
        "**1ï¸âƒ£ Chat**\n",
        "\n",
        "Means conversation\n",
        "\n",
        "Multiple messages\n",
        "\n",
        "Roles like:user,assistant,system\n",
        "\n",
        "**2ï¸âƒ£ Completion**\n",
        "\n",
        "The model completes the conversation\n",
        "\n",
        "It predicts what should be said next\n",
        "\n",
        "So together:\n",
        "\n",
        "**Chat Completion = Completing the next message in a chat**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6awV0VGaRtO4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# questions"
      ],
      "metadata": {
        "id": "AqSlQglQR0l8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. what is an api**\n",
        "\n",
        "=>An Appliaction Programming interface allows two software systems to communicate.\n",
        "it is a bridge that let your program to talk to another device.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**2. What is an API Key**\n",
        "\n",
        "=>An API Key is a secret token used to autheticate and autorize a user while accessing an api\n",
        "it tells the api who you are and what access you have.\n",
        "\n",
        "---\n",
        "\n",
        "**3.why should be api keys be kept secret?**\n",
        "\n",
        "=> if someone gets your API key they can\n",
        "\n",
        "*use your quota\n",
        "\n",
        "*generate bills\n",
        "\n",
        "*misuse your account\n",
        "\n",
        "so api keys should be stored secretlyin envirnment variables\n",
        "instead of code.\n",
        "\n",
        "```\n",
        "ex os.getenv(\"GROQ_API_KEY\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "**4. WHY DO WE USE .ENV OR USERDATA IN COLLAB**\n",
        "\n",
        "=>\n",
        "Because they:  \n",
        "1.hide secret keys\n",
        "\n",
        "2.code can be shared secretely\n",
        "\n",
        "3.keys can be changed without modifying code\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "L-yyVx4BR5Uh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat Completion Fundamentals"
      ],
      "metadata": {
        "id": "SqbeqIcuUyfI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. What is chat completion Model?**\n",
        "\n",
        "=>A Chat Completion model generates responces based on  :    \n",
        "1 System instructions\n",
        "\n",
        "2 User messages\n",
        "\n",
        "3 Conversation history\n",
        "\n",
        "it is designed for **Conversion based tasks**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**8. Difference between Text Completion and chat Completion?**\n",
        "\n",
        "\n",
        "=>Text Completion.........          chat Completion\n",
        "\n",
        "TC:single prompt .........          CC:Multi-message\n",
        "\n",
        "\n",
        "TC:No roles      .................   CC: userroles(System,user,assistant)\n",
        "\n",
        "TC:No Memory     .........          CC: Support conversation\n",
        "\n",
        "---\n",
        "\n",
        "**9. What are roles in chat completion?**\n",
        "\n",
        "=>\n",
        "System=rules and behaviour\n",
        "\n",
        "User=instructions and Questions\n",
        "\n",
        "Assistant=AI Responses\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**10. Why is System Role important ?**\n",
        "\n",
        "\n",
        "=>it set the behaviour and personality of the model.\n",
        "for ex\n",
        "```\n",
        "You are a helpful AI Agent\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "**11. Can the model remember Past conversaction automatically?.**\n",
        "\n",
        "\n",
        "=>No\n",
        "\n",
        "The model is stateless\n",
        "\n",
        "We must send conversaction history every time.\n",
        "\n"
      ],
      "metadata": {
        "id": "JYtDoen6VMSZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GROQ + LLM Basics"
      ],
      "metadata": {
        "id": "2JDRuczLbDjB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**12.what is Groq**\n",
        "\n",
        "=>\n",
        "Groq is an AI interface platform optimized for ultra fast LLM execution using LPU hardware.\n",
        "\n",
        "---\n",
        "\n",
        "**13. Why use Groq instead of OpenAI?**\n",
        "\n",
        "=>\n",
        "\n",
        "Faster Responce\n",
        "\n",
        "Free tier\n",
        "\n",
        "Low latency\n",
        "\n",
        "Open models(LLaMA)\n",
        "\n",
        "---\n",
        "\n",
        "**14. What is LLaMA?**\n",
        "\n",
        "=>\n",
        "LLaMA is a Family of open-source language models developed by Meta.\n",
        "\n",
        "---\n",
        "\n",
        "**15.what does this mean?**\n",
        "\n",
        "```\n",
        "model=\"llama-3.1-8b-instant\"\n",
        "```\n",
        "\n",
        "\n",
        "**=>**\n",
        "\n",
        "3.1=>model version\n",
        "\n",
        "8b=>8billion parameters\n",
        "\n",
        "instant=>optimized for speed\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**16. Why did older models fails?**\n",
        "\n",
        "\n",
        "=>\n",
        "They were decommissioned and no longer supported by Groq\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pz7pepLKbN5_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent Fundamentals"
      ],
      "metadata": {
        "id": "7S3zoGpnglRi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**17. What is an AI Agent?**\n",
        "=> An AI Agent is an autonomous entity that:\n",
        "\n",
        "observe input\n",
        "\n",
        "Think using an LLM\n",
        "\n",
        "Acts by generating output\n",
        "\n",
        "Maintains memory\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**18. Difference**"
      ],
      "metadata": {
        "id": "iMYx_ltugqjf"
      }
    }
  ]
}